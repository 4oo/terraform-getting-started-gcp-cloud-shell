# Getting Started with Terraform on Google Cloud Platform

## Introduction

### About this guide

This guide will help you quickly learn the fundamentals of Terraform and using it to provision infrastructure on Google Cloud Platform (GCP).

As you follow this guide, you'll use Terraform to provision, update, and destroy a simple set of infrastructure using the sample configuration provided.

The sample configuration provisions networking resources and rules, storage, and a basic Linux virtual machine. You'll also learn about Terraform modules, remote backends, outputs, and provisioners. These are the building blocks for more complex configurations.

### Google Cloud Shell

This guide uses Google Cloud Shell to give you an environment preconfigured with Terraform. You can run commands at the command prompt, and edit the files in the editor window.

If you'd prefer to follow this tutorial on your local machine, you can follow this [guide on learn.hashicorp.com](https://learn.hashicorp.com "FIXME: Add learn link").

## Installing Terraform

Terraform is already install in your Cloud Shell environment. You can verify this by running:

```shell
terraform --version
```

If you'd like to install Terraform on your local machine, you can [follow the instructions here](https://learn.hashicorp.com "FIXME: Add learn link").

### Note: Terraform versions

When running the previous command, you may see a warning that there is a newer version of Terraform available. This guide has been tested with the version of Terraform installed in your Cloud Shell environment, so please continue to use it for the rest of the guide.

## Setting Up

With Terraform installed, let's dive right into it and start creating
some infrastructure.

We'll build infrastructure on
[GCP](https://cloud.google.com) for this getting started guide, but Terraform
can manage many other things using [providers](https://www.terraform.io/docs/providers/index.html).
Some examples of this are in the
[use cases section](https://www.terraform.io/intro/use-cases.html).

### Warning: Cost

While everything provisioned in this guide should fall within GCP's free tier, if you provision resources outside of the free tier, you may be charged. We cannot be responsible for any charges you may incur.

### Setting up GCP

In addition to a GCP account, you'll need two things to use Terraform to provision your infrastructure:

- **A GCP Project.** GCP organizes resources into projects. You can use an existing project or [create one now](https://console.cloud.google.com/projectcreate) in the GCP console. You'll need the `project ID` later. You can see a list of your projects in the [cloud resource manager](https://console.cloud.google.com/cloud-resource-manager).

- **Authentication.** When we're using Google Cloud Shell, the shell is already configured to authenticate with your GCP account. When using Terraform from another environment, you'll need to configure authentication. You can [read about credentials here](https://www.terraform.io/docs/providers/google/provider_reference.html#credentials).

## Terraform Configuration

The set of files used to describe infrastructure in Terraform is
known as a Terraform _configuration_. We're going to write our first
configuration now. Our goal for now is to launch a single compute instance.

The format of the configuration files is
[documented here](https://www.terraform.io/docs/configuration/index.html).
Configuration files can
[also be JSON](https://www.terraform.io/docs/configuration/syntax.html), but we recommend only using JSON when the configuration is generated by a machine.

The entire configuration is shown below. We'll go over each part after.

When run, Terraform will load all configuration files from the current directory. So it's a good idea to have a separate directory for each project. Your Cloud Shell environment should include a directory called `sample-project`.

Inside of it there should be a file named `main.tf`. Terraform recognizes files ending in `.tf` or `.tf.json` as configuration files and will load them when it runs.

First, we'll configure the provider. Add the following to `main.tf`:

```hcl
provider "google" {
  project = "YOUR-PROJECT-ID"
  region  = "us-central1"
  zone    = "us-central1-c"
}
```

You'll need to replace the project with the project id of the project you created earlier. Remember you can see a list of your projects in the [cloud resource manager](https://console.cloud.google.com/cloud-resource-manager)

The `provider` block is used to configure the named provider, in
our case `google`. A provider is responsible for creating and
managing resources. Multiple provider blocks can exist if a
Terraform configuration manages resources from different providers.

### Initialization

The first command to run for a new configuration -- or after checking out
an existing configuration from version control -- is `terraform init`, which
initializes various local settings and data that will be used by subsequent
commands.

Terraform uses a plugin based architecture to support the numerous infrastructure and service providers available. The `terraform init` command will automatically download and install any provider binary for the providers in use within the configuration, which in this case is the `google` provider.

Run the command now:

```
terraform init
```

You should see several lines of output, including:

```
Terraform has been successfully initialized!
```

This lets us know that Terraform is working correctly.

## Applying Configuration

The _provider_ block we created just now doesn't actually provision any resources. For that, we'll use _resource_ blocks. The first resource we'll create will configure the services we'll use for the rest of the guide.

### Enabling Services

We'll use a few different Google Cloud services in this guide. We need to enable them before we can use them. To do so, we'll also introduce our first resource. You can learn more about how this resource works from [the documentation](https://www.terraform.io/docs/providers/google/r/google_project_services.html).

Add the following to your main.tf file:

```hcl
resource "google_project_services" "project_services" {
  project  = "YOUR-PROJECT-ID"
  services = ["compute.googleapis.com", "oslogin.googleapis.com"]
}
```

The `resource` block defines a resource that exists within your infrastructure. A resource might be a physical or virtual component such as a server, or a logical resource such as a Google App Engine application, or configuration, which is what this one is. It enables the listed services for your project.

To apply your changes, run:

```sh
$ terraform apply
```

You should see output like this:
```
$ terraform apply
An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
Terraform will perform the following actions:
  # google_project_services.project_services will be created
  + resource "google_project_services" "project_services" {
      + disable_on_destroy = true
      + id                 = (known after apply)
      + project            = "just-center-247116"
      + services           = [
          + "compute.googleapis.com",
        ]
    }
Plan: 1 to add, 0 to change, 0 to destroy.
Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.
  Enter a value:
```

Respond with `yes`. When you do, you should see further output like this:

```
...
Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.
  Enter a value: yes
google_project_services.project_services: Creating...
google_project_services.project_services: Creation complete after 7s [id=just-center-247116]
Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
```

Adding this resource is the equivalent of navigating to the appropriate page in the [api library](https://console.developers.google.com/apis/library/compute.googleapis.com) and enabling the services there.

You may also have noticed that we have to repeat the project ID. Don't worry, we'll fix that soon when we learn about _variables_.

## Provisioning Resources

Now we'll create our first "real" resource: A Virtual Private Network. Add the following to your `main.tf` file:

```hcl
resource "google_compute_network" "vpc_network" {
  name       = "terraform-network"
  depends_on = [google_project_services.project_services]  
}
```

This is an example of a more common use for resources. We'll use this network for resources we create later in this guide.

The resource block has two strings before opening the block: the resource type and the resource name. In our example, the resource type is "google_compute_network" and the name is "vpc_network". The prefix of the type maps to the provider. In our case "google_compute_network" automatically tells Terraform that it is managed by the "google" provider. The resource type and name together form the resource ID, in this case "google_compute_network.vpc_network". The resource can be referenced by this ID in other parts of your configuration.

Within the resource block itself is configuration for that resource. This is dependent on each resource provider and is fully documented within our [providers reference](https://www.terraform.io/docs/providers/index.html). For our network, we just specify the name, which will be how the network is identified in GCP. You may want to explore the documentation to find the reference for `google_compute_network` and compare it to what's shown here.

### Creating Resources

Run `terraform apply` again. You should see output similar to this:

```
...
Terraform will perform the following actions:
  # google_compute_network.vpc_network will be created
  + resource "google_compute_network" "vpc_network" {
      + auto_create_subnetworks         = true
      + delete_default_routes_on_create = false
      + gateway_ipv4                    = (known after apply)
      + id                              = (known after apply)
      + name                            = "terraform-network"
      + project                         = (known after apply)
      + routing_mode                    = (known after apply)
      + self_link                       = (known after apply)
    }
Plan: 1 to add, 0 to change, 0 to destroy.
...
```

This output shows the _execution plan_, describing which actions Terraform will take in order to change real infrastructure to match the configuration. The output format is similar to the diff format generated by tools such as Git. The output has a `+` next to `resource "google_compute_network" "vpc_network"`, meaning that Terraform will create this resource. Beneath that, it shows the attributes that will be set. When the value displayed is `(known after apply)`, it means that the value won't be known until the resource is created.

If `terraform apply` failed with an error, read the error message and fix the error that occurred. At this stage, it is likely to be a syntax error in the configuration.

If the plan was created successfully, Terraform will now pause and wait for approval before proceeding. If anything in the plan seems incorrect or dangerous, it is safe to abort here with no changes made to your infrastructure.

In this case the plan looks acceptable, so type `yes` at the confirmation prompt to proceed.

Executing the plan will take a few minutes since Terraform waits for the network to be created successfully:

```sh
# ...
  Enter a value: yes

google_compute_network.vpc_network: Creating...
google_compute_network.vpc_network: Still creating... [10s elapsed]
google_compute_network.vpc_network: Still creating... [20s elapsed]
google_compute_network.vpc_network: Still creating... [30s elapsed]
google_compute_network.vpc_network: Still creating... [40s elapsed]
google_compute_network.vpc_network: Still creating... [50s elapsed]
google_compute_network.vpc_network: Creation complete after 58s [id=terraform-network]

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
```

After this, Terraform is all done! You can go to the GCP console to see the
created network. Make sure you're looking at the same region and project that was configured in the provider configuration!

If you look in your working directory, you'll see that Terraform also wrote some data into the `terraform.tfstate` file. This state file is extremely important; it keeps track of Terraform's understanding of the resources it created. This file must be saved and distributed to anyone who might run Terraform. When using Terraform in production, it's recommended that you [setup remote state](https://www.terraform.io/docs/state/remote.html) to store and share the state with your teams, but this is not necessary for simple situations like this Getting Started guide.

## Inspecting State

You can inspect the current state by running `terraform show`:

```sh
$ terraform show
# google_compute_network.vpc_network:
resource "google_compute_network" "vpc_network" {
    auto_create_subnetworks         = true
    delete_default_routes_on_create = false
    id                              = "terraform-network"
    name                            = "terraform-network"
    project                         = "just-center-247116"
    routing_mode                    = "REGIONAL"
    self_link                       = "https://www.googleapis.com/compute/v1/projects/just-center-247116/global/networks/terraform-network"
}
# google_project_services.project_services:
resource "google_project_services" "project_services" {
    disable_on_destroy = true
    id                 = "just-center-247116"
    project            = "just-center-247116"
    services           = [
        "compute.googleapis.com",
        "oslogin.googleapis.com",
    ]
}
```

You can see that by creating our resources, we've also gathered
a lot of information about them. These values can actually be referenced
to configure other resources or outputs, which will be covered later in
this guide.

## Changing Infrastructure

In the previous step, you created your first infrastructure with
Terraform: a VPC network. In this page, we're going to
modify your configuration, and see how Terraform handles change.

Infrastructure is continuously evolving, and Terraform was built
to help manage and enact that change. As you change Terraform
configurations, Terraform builds an execution plan that only
modifies what is necessary to reach your desired state.

By using Terraform to change infrastructure, you can version
control not only your configurations but also your state so you
can see how the infrastructure evolved over time.

### Adding Resources

We can add resources to our configuration. You can configure a compute instance by adding the following to `main.tf`:

```hcl
resource "google_compute_instance" "vm_instance" {
  name         = "terraform-instance"
  machine_type = "f1-micro"

  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-9"
    }
  }

  network_interface {
    network = google_compute_network.vpc_network.name
    access_config {
    }
  }
}
```

We're setting a few more arguments this time. The name and machine type are simple strings, but `boot_disk` and `network_interface` are more complex _blocks_. You can see all of the available options [in the documentation](https://www.terraform.io/docs/providers/google/r/compute_instance.html). For this example, we'll use a Debian operating system, and the network interface we created earlier. Notice how we refer to the new network's name property with `google_compute_network.vpc_network.name` -- `google_compute_network.vpc_network` is the ID, matching the values in the block that defines the network, and `name` is a property of that resource.

The presence of the `access_config` block, even without any arguments, ensures that the instance will be accessible over the internet.

Now, apply the change by running `terraform apply` again. You should see that terraform plans to add the new instance. Once again type `yes` at the prompt to confirm this change.

## Changing Resources

Let's change the disk image of our instance. Edit the `boot_disk` block inside your `vm_instance` resource your configuration file and change it to the following:

```hcl
  boot_disk {
    initialize_params {
      image = "cos-cloud/cos-stable"
    }
  }
```

We've changed the boot disk from being a Debian 9 image to use Google's Container-Optimized OS. When you update your Terraform configuration like this, the next time you run `terraform apply`, Terraform will notice the change and update your infrastructure to match the new configuration.

### Apply Changes

After changing the configuration, run `terraform apply` again to see how
Terraform will apply this change to the existing resources:

```sh
terraform apply
```

You should see output like this:

```
...
  # google_compute_instance.vm_instance must be replaced
-/+ resource "google_compute_instance" "vm_instance" {
        can_ip_forward       = false
      ~ cpu_platform         = "Intel Haswell" -> (known after apply)
        deletion_protection  = false
      ~ guest_accelerator    = [] -> (known after apply)
      ~ id                   = "terraform-instance" -> (known after apply)
      ~ instance_id          = "2506428060139560363" -> (known after apply)
      ~ label_fingerprint    = "42WmSpB8rSM=" -> (known after apply)

...

          ~ initialize_params {
              ~ image = "https://www.googleapis.com/compute/v1/projects/debian-cloud/global/images/debian-9-stretch-v20190618" -> "cos-cloud/cos-stable" # forces replacement
              ~ size  = 10 -> (known after apply)
              ~ type  = "pd-standard" -> (known after apply)
            }
```

The prefix `-/+` means that Terraform will destroy and recreate
the resource, rather than updating it in-place. While some attributes
can be updated in-place (which are shown with the `~` prefix), changing the
boot disk image for a VM instance requires recreating it. Terraform and the GCP provider handle these details for you, and the execution plan makes it clear what Terraform will do.

Additionally, the execution plan shows that the disk image change is what
required our instance to be replaced. Using this information,
you can adjust your changes to possibly avoid destroy/create updates
if they are not acceptable in some situations.

Once again, Terraform prompts for approval of the execution plan before
proceeding. Answer `yes` to execute the planned steps. In the following output, as indicated by the execution plan, you'll see that Terraform first destroyed the existing instance and then created a new one in its place. You can use `terraform show` again to see the new values associated with this instance.

## Destroying Infrastructure

Terraform can also destroy infrastructure. Try commenting out the `"google_compute_instance" "vm_instance"` block, and re-run `terraform apply`. You should see that Terraform plans to remove this resource.

We want to keep our instance, so for now, answer `no` to the prompt, and uncomment the lines once again.

Terraform can also destroy all of the configured infrastructure with the `terraform destroy` command. Don't run this command yet, though, since we still have more work to do with this configuration.

## Resource Dependancies

In this section, we're going to learn more about resource dependencies and how to use resource parameters to share information about one resource with other resources.

On this page, we'll show a basic example of how to configure multiple resources and how to reference the attributes of other resources to configure other resources.

### Assigning an Elastic IP

Now we'll improve your configuration by assigning an elastic IP to
the VM instance we're managing. Modify your `main.tf` and
add the following:

```hcl
resource "google_compute_address" "vm_static_ip" {
  name = "terraform-static-ip"
}
```

This should look familiar from the earlier example of adding a VM instance
resource, except this time we're creating an "google_compute_address" resource
type. This resource type allocates a [static IP address](https://cloud.google.com/compute/docs/ip-addresses/#reservedaddress)
to your project.

You can see what will be created by creating a terraform _plan_. Run this command now:

```sh
terraform plan
```

You should see output like this:

```
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.

google_compute_network.vpc_network: Refreshing state... [id=terraform-network]
google_compute_instance.vm_instance: Refreshing state... [id=terraform-instance]

------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_compute_address.vm_static_ip will be created
  + resource "google_compute_address" "vm_static_ip" {
      + address            = (known after apply)
      + address_type       = "EXTERNAL"
      + creation_timestamp = (known after apply)
      + id                 = (known after apply)
      + name               = "terraform-static-ip"
      + network_tier       = (known after apply)
      + project            = (known after apply)
      + region             = (known after apply)
      + self_link          = (known after apply)
      + subnetwork         = (known after apply)
      + users              = (known after apply)
    }

Plan: 1 to add, 0 to change, 0 to destroy.
```

Terraform plan works like the first step of _apply_; it tells you what changes will be made if you were to run `terraform apply` without actually making any changes.

Notice that the only change we're making is to add a static IP. What we want is to attach the IP address to your instance.

Update the `network_interface` configuration for your instance like so:

```hcl
  network_interface {
    network = google_compute_network.vpc_network.self_link
    access_config {
      nat_ip = google_compute_address.vm_static_ip.address
    }
  }
```

The [access_config](https://www.terraform.io/docs/providers/google/r/compute_instance.html#access_config) block has several optional arguments, and in this case we'll set `nat_ip` to be the static IP address. When Terraform reads this configuration, it will:

1. Ensure that `vm_static_ip` is created before `vm_instance`
1. Save the properties of `vm_static_ip` in the state
1. Set `nat_ip` to the value of the `vm_static_ip.address` property
1. Since the network configuration can be updated in-place, Terraform will change the existing resource rather than destroying and re-creating it.

### Plan Changes

We'll run `terraform plan` again, but this time, let's save the plan. Run this command:

```sh
terraform plan -out static_ip
```

You should see output similar to this:

```
$ terraform plan -out static_ip
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.

google_compute_network.vpc_network: Refreshing state... [id=terraform-network]
google_compute_instance.vm_instance: Refreshing state... [id=terraform-instance]

------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
  ~ update in-place

Terraform will perform the following actions:

  # google_compute_address.vm_static_ip will be created
  + resource "google_compute_address" "vm_static_ip" {
      + address            = (known after apply)
      + address_type       = "EXTERNAL"
...

  # google_compute_instance.vm_instance will be updated in-place
  ~ resource "google_compute_instance" "vm_instance" {
        can_ip_forward       = false
        cpu_platform         = "Intel Haswell"
        deletion_protection  = false
...
          ~ access_config {
              ~ nat_ip       = "34.66.211.126" -> (known after apply)
                network_tier = "PREMIUM"
...
Plan: 1 to add, 1 to change, 0 to destroy.

------------------------------------------------------------------------

This plan was saved to: static_ip

To perform exactly these actions, run the following command to apply:
    terraform apply "static_ip"
```

Saving the plan this way ensures that we can apply exactly the same plan in the future. If we try to apply the file created by the plan, Terraform will first check to make sure the exact same set of changes will be made before applying the plan.

In this case, we can see that Terraform will create a new
`google_compute_address` and update the existing VM to use it.

### Apply Changes

To have Terraform apply this change, run:

```sh
terraform apply "static_ip"
```

As shown above, Terraform created the static IP before modifying the VM instance. Since we're applying a pre-existing plan, Terraform would fail if the plan couldn't be applied exactly as-is. You'll also notice that Terraform doesn't ask you to confirm the plan, since you're applying a saved plan.

## Dependancies

Usually, some parts of your infrastructure will depend on one another. You can't create a virtual machine without having a network for it to reside in. Handling depedancies is a key part of how Terraform manages your infrastructure.

### Implicit Dependancies

By studying the resource attributes used in interpolation expressions, Terraform can automatically infer when one resource depends on another. In the example above, the reference to `google_compute_address.vm_static_ip.address` creates an _implicit dependency_ on the `google_compute_address` named `vm_static_ip`.

Terraform uses this dependency information to determine the correct order in which to create and update different resources. In the example above, Terraform knows that the `vm_static_ip` must be created before the `vm_instance` is updated to use it.

Implicit dependencies via interpolation expressions are the primary way
to inform Terraform about these relationships, and should be used whenever
possible.

### Explicit Dependencies

Sometimes there are dependencies between resources that are _not_ visible to
Terraform. The `depends_on` argument is accepted by any resource and accepts
a list of resources to create _explicit dependencies_ for.

For example, you may have noticed that the "vpc_network" we created earlier includes a directive that says it depends on the "project_services" resource. We need these services enabled for our project to create our resources, but there isn't an implicit mapping between the resources we're configuring and the services that need to be enabled to make them work.

## Provisioning

The compute instance we launched at this point is based on the Google image
given, but has no additional software installed or configuration applied.

Instead of using a default image, if you're running an image-based infrastructure (for instance, by creating images with [Packer](https://www.packer.io)), then an instance using one of your images will be launched with all the software and configuration it needs.

In general, we recommend that you use a tool like Packer so that your infrastructure requires little or no provisioning after it's deployed. Managing your infrastructure this way is sometimes called _immutable infrastructure_, and can help ensure your infrastructure is more robust and fault tolerant.

That said, many infrastructures still require some sort of initialization or software provisioning step. Terraform uses _provisioners_ to upload files, run shell scripts, or install and trigger other software like configuration management tools.

### Defining a Provisioner

To define a provisioner, modify the resource block defining the `vm_instance` to
look like the following:

```hcl
resource "google_compute_instance" "vm_instance" {
  name         = "terraform-instance"
  machine_type = "f1-micro"

  provisioner "local-exec" {
    command = "echo ${google_compute_instance.vm_instance.network_interface[0].access_config[0].nat_ip} > ip_address.txt"
  }

# ...
```

Be sure to leave the `boot_disk` and `network_interface` blocks unchanged.

This adds a `provisioner` block within the `resource` block. Multiple
`provisioner` blocks can be added to define multiple provisioning steps.
Terraform supports
[many provisioners](https://www.terraform.io/docs/provisioners/index.html),
but for this example we are using the `local-exec` provisioner.

The `local-exec` provisioner executes a command locally on the machine running Terraform, not the VM instance itself. This also shows a fairly complex example of string interpolation. Within a string in our Terraform configuration, we can refer to attributes of our configuration using the `${}` interpolation syntax. The value inside the curly braces is used as a reference to your configuration, and the value is replaced within the string when Terraform interprets your configuration.

In this example, each VM instance can have multiple network interfaces, so we refer to the first one with `network_interface[0]` - counting starting from 0, as most programming languages do. Each network interface can have multiple access_config blocks as well, so once again we specify the first one.

## Running Provisioners

Provisioners are only run when a resource is _created_. They are not a
replacement for configuration management and changing the software of an
already-running server, and are instead a way to bootstrap a server when it is
first created.

If you were to run `terraform apply` at this point, the results may be confusing at first:

```sh
$ terraform apply
google_compute_network.vpc_network: Refreshing state... [id=terraform-network]
google_compute_address.vm_static_ip: Refreshing state... [id=hc-training-test/us-central1/terraform-static-ip]
google_storage_bucket.example_bucket: Refreshing state... [id=example-bucket-robin-jul-9-2019]
google_compute_instance.another_instance: Refreshing state... [id=terraform-instance-2]
google_compute_instance.vm_instance: Refreshing state... [id=terraform-instance]

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.
```

Terraform found nothing to do - and if you check, you'll find that there's no
`ip_address.txt` file on your local machine.

Terraform treats provisioners differently from other properties. Provisioners
only run when a resource is created, but adding a provisioner does not force
that resource to be destroyed and recreated. If this is what we want, we can use `terraform taint`. Run the following command:

```sh
terraform taint google_compute_instance.vm_instance
```

A _tainted_ resource will be destroyed and recreated during the next _apply_. Run the apply command now:

```
terraform apply
```

As usual, answer `yes` when prompted to confirm the change.

You can verify everything worked by looking at the `ip_address.txt` file:

```sh
$ cat ip_address.txt
104.154.236.90
```

It contains the IP, just as we asked!

## Failed Provisioners and Tainted Resources

If a resource is successfully created but fails a provisioning step, Terraform
will error and mark the resource as _tainted_. A resource that is tainted still exists, but can't be considered safe to use since provisioning failed.

When you generate your next execution plan, Terraform will remove any tainted
resources and create new resources, attempting to provision them again after
creation.

### Destroy Provisioners

Provisioners can also be defined that run only during a destroy
operation. These are useful for performing system cleanup, extracting
data, etc.

For many resources, using built-in cleanup mechanisms is recommended
if possible (such as init scripts), but provisioners can be used if
necessary.

This guide won't show any destroy provisioner examples.
If you need to use destroy provisioners, please
[see the provisioner documentation](https://www.terraform.io/docs/provisioners).

## Variables

You now have enough Terraform knowledge to create useful configurations, but we're still hard-coding our Project ID, AMIs, etc. To become truly shareable and version controlled, we need to parameterize the configurations. This page introduces input variables as a way to do this.

### Defining Variables

Let's first extract a few of the hardcoded values into variables.

Add the following to `variables.tf`:

```hcl
variable "project" { }

variable "region" {
  default = "us-central1"
}

variable "zone" {
  default = "us-central1-c"
}
```

**Note**: Terraform loads all files ending in `.tf` in a directory, so it doesn't matter to terraform where your variables are defined. We recommend defining them in their own file to make your configuration easier to organize and understand.

This defines three variables within your Terraform configuration. The first one has an empty block: `{}`. The other two set defaults. If a default value is set, the variable is optional. Otherwise, the variable is required. If you run `terraform plan` now, Terraform will prompt you for the values for the "project" variable.

## Using Variables in Configuration

Next, update the GCP provider configuration in `main.tf` to the following:

```hcl
provider "google" {
  project = var.project
  region  = var.region
  zone    = var.region
}
```

And update the "project_services" configuration to use `var.project` instead of hard coding the project id:

```hcl
resource "google_project_services" "project_services" {
  project  = var.project
  services = ["compute.googleapis.com", "oslogin.googleapis.com"]
}
```

Variables are referenced with the `var.` prefix. Terraform will replace the reference with the value of the given variable.

### Assigning Variables

There are several ways to assign variables, depending on your needs.

#### Command-line flags

You can set variables directly on the command-line with the
`-var` flag. Any command in Terraform that inspects the configuration
accepts this flag, such as `apply`, `plan`, and `refresh`:

```sh
terraform plan -var 'project=YOUR-PROJECT-ID'
```

**Note**: Be sure to set your project ID here.

Setting variables this way will not save them, and they'll have to be passed
this way every time you run terraform.

#### From a file

To persist variable values, create a file and assign variables within
this file. Add the following to `terraform.tfvars`:

```hcl
project = "YOUR-PROJECT-ID"
```

Terraform automatically loads all files which match `terraform.tfvars` or `*.auto.tfvars` present in the current directory to populate variables. You can also specify a file to load with the `-var-file` commandline argument.

These files are the same syntax as Terraform configuration files. And like
Terraform configuration files, these files can also be JSON.

For security reasons, we recommend never saving usernames and passwords to version control. Your terraform configuration will probably need these secret values, though. One solution is to create a local secret variables file and use `-var-file` to load it.

You can also use multiple `-var-file` arguments in a single command, with some
checked in to version control and others not checked in. For example:

```sh
$ terraform apply \
  -var-file="secret.tfvars" \
  -var-file="production.tfvars"
```

#### From environment variables

Terraform will read environment variables in the form of `TF_VAR_name`
to find the value for a variable. For example, the `TF_VAR_region`
environment variable can be set to set the `region` terraform variable.

**Note**: Environment variables can only populate string-type variables.
List and map type variables must be populated via one of the other mechanisms.

#### Variable Defaults

If no value is assigned to a variable via any of the methods described above, and the variable has a `default` key in its declaration, that value will be used for the variable.

#### UI Input

Finally, if you execute a terraform command with some variables unspecified, Terraform will ask you to input their values interactively. These values are not saved, but this provides a convenient workflow when getting started with Terraform. UI Input is not recommended for everyday use of Terraform.

**Note**: UI Input is only supported for string variables. List and map variables must be populated via one of the other mechanisms.

## Variable Types

Terraform supports a number of different variable types. The most common ones
are described below, and you can read the [Terraform documentation](https://www.terraform.io/docs/configuration/variables.html) for a complete list.

### Strings

If no type is specified, then Terraform assumes a variable is a _string_. Like
most programming languages, strings are just a sequence of characters. You can
also explicitly define a variable as a string. Update `variables.tf` like so:

```hcl
variable "project" {
  type = string
}
```

This usually isn't necessary, though, since the string type would otherwise be
assumed.

### Numbers

A _number_, like a string, is pretty straightforward. Any valid integer or floating point value is allowed. When processing your configuration, Terraform will generally do the right thing when converting from a string to a number. So defining the number type is more about ensuring the correct type of input is used.

Add a new variable to `variables.tf`:

```hcl
variable "web_instance_count" {
  type = number
  default = 1
}
```

### Lists

A list is a sequence of values. Lists are defined either explicitly or
implicitly. Add one of the following variable definitions to `variables.tf`:

```hcl
# implicitly set type by using brackets [...]
variable "cidrs" {
  default = []
}

# explicitly set type
variable "cidrs" {
  type = list
}
```

You can specify list values in `terraform.tfvars` file as well. Add the following line:

```hcl
cidrs = [ "10.0.0.0/16", "10.1.0.0/16" ]
```

### Maps

Maps are a way to create variables that are lookup tables. An example will show this best. In our configuration, we've hard-coded the machine type to `f1-micro`. We might want different machine types for some environments. We can use a map to accomplish this.

Add the following to your `variables.tf` file:

```hcl
variable "environment" {
  type = string
  default = "dev"
}

variable "machine_types" {
  type = "map"
  default = {
    "dev"  = "f1-micro"
    "test" = "n1-highcpu-32"
    "prod" = "n1-highcpu-32"
  }
}
```

Like lists, a variable can have a map type assigned explicitly, or it can be implicitly declared as a map by specifying a default value that is a map.

Now, update your `vm_instance` in `main.tf` as follows:

```hcl
resource "google_compute_instance" "vm_instance" {
  name         = "terraform-instance"
  machine_type = var.machine_types[var.environment]

# ...
```

The square-bracket index notation used here is how the `map` type is accessed as a variable.

Run `terraform plan`. Because of the default value we used for `environment`,
you should see that there are no changes to apply.

The `map` type expression can also use a static value lookup directly with
`var.machine_types["dev"]`.

#### Assigning Maps

We set defaults above, but maps can also be set using the `-var` and
`-var-file` values. For example:

```sh
$ terraform plan -var 'machine_types={ "dev" = "f1-micro", test = "n1-standard-16", prod = "n1-standard-16" }'
# ...
```

**Note**: Even if every key will be assigned as input, the variable must be
established as a map in your configuration by setting the type or its default
value to a map with `{}`.

Here is an example of setting a map's keys from a file. Starting with these
variable definitions:

```hcl
variable "region" {}
variable "machine_types" {
  type = "map"
}
```

Instead of setting the default value was we did, you could specify values in a `terraform.tfvars` file:

```hcl
machine_types = {
  "dev"  = "f1-micro"
  "test" = "n1-highcpu-32"
  "prod" = "n1-highcpu-32"
}
```

These last few changes shouldn't have made any difference to your Terraform configuration, since the default values we specified match the values that were hard coded. Before you move on, verify that this is the case by running:

```sh
terraform plan
```

## Outputs

In the previous section, we introduced input variables as a way to parameterize Terraform configurations. In this page, we'll introduce output variables as a way to organize data to be easily queried and shown back to the Terraform user.

When building potentially complex infrastructure, Terraform stores hundreds or thousands of attribute values for all your resources. But as a user of Terraform, you may only be interested in a few values of importance, such as a load balancer IP, VPN address, etc.

Outputs are a way to tell Terraform what data is important. This data is printed to the console when `apply` is called, and can be queried using the `terraform output` command.

### Defining Outputs

Let's define an output to show us the static IP address that we created. Open `outputs.tf` and add the following contents:

```hcl
output "ip" {
  value = google_compute_address.vm_static_ip.address
}
```

**Note**: Just like `variables.tf`, this configuration could go in your
`main.tf` file. We're putting it in a separate file just to keep things
organized.

This defines an output variable named "ip". The name of the variable must
conform to Terraform variable naming conventions if it is to be used as an input
to other modules. The `value` field specifies what the value will be, In this
case, we're outputting the `public_ip` attribute of the elastic IP address.

Multiple `output` blocks can be defined to specify multiple output variables.

### Viewing Outputs

Run `terraform apply` to populate the output. This only needs to be done once after the output is defined. The apply output should change slightly. At the end you should see this:

```shell
$ terraform apply
...

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

ip = 104.154.236.90
```

`apply` highlights the outputs. You can also query the outputs after apply-time using `terraform output`:

```sh
$ terraform output ip
104.154.236.90
```

This command is useful for scripts to extract outputs.

## Modules

_Work in progress_

## Remote State

You have now seen how to build, change, and destroy infrastructure from a local machine. This is great for testing and development, but in production environments it is more responsible to share responsibility for infrastructure. The best way to do this is by running Terraform in a remote environment with shared access to state.

Terraform supports team-based workflows with a feature known as [remote
backends](https://www.terraform.io/docs/backends/index.html). Remote backends
allow Terraform to use a shared storage space for state data, so any member of
your team can use Terraform to manage the same infrastructure.

Depending on the features you wish to use, Terraform has multiple remote backend options. HashiCorp recommends using [Terraform Cloud](https://learn.hashicorp.com/terraform/cloud/tf_cloud_gettingstarted.html). Terraform Cloud offers free state management with no limits on users, workspaces, locking, and HashiCorp Vault encryption.

[Terraform Enterprise](https://www.hashicorp.com/products/terraform/?utm_source=oss&utm_medium=getting-started&utm_campaign=terraform) is HashiCorp's enterprise solution and also acts as a remote backend. Terraform Enterprise allows teams to easily version, audit, and collaborate on infrastructure changes. Each proposed change generates a Terraform plan which can be reviewed and collaborated on as a team. When a proposed change is accepted, the Terraform logs are stored, resulting in a linear history of infrastructure states to help with auditing and policy enforcement. Additional benefits to running Terraform remotely include moving access credentials off of developer machines and freeing local machines from long-running Terraform processes.

## Working With Remote State

First, we'll use Terraform Cloud as our backend. Terraform Cloud offers free remote state management. Terraform Cloud is the recommended best practice for remote state storage.

If you don't have an account, please [sign up here](https://app.terraform.io/signup) for an account to use with this guide. For more information on Terraform Cloud, [view our getting started guide](https://learn.hashicorp.com/terraform/cloud/tf_cloud_gettingstarted.html).

When you sign up for Terraform Cloud, you'll create an organization. Make a note of the organization's name.

Next, configure the backend in your `main.tf` file with the organization name, and a new workspace name of your choice:

```hcl
terraform {
  backend "remote" {
    organization = "Example-Org-Name"

    workspaces {
      name = "Example-Workspace"
    }
  }
}
```

You'll also need a user token to authenticate with Terraform Cloud. You can
generate one on the [user settings page](https://app.terraform.io/app/settings/tokens).

Copy the user token to your clipboard, and create a Terraform CLI Configuration file <walkthrough-editor-open-file filePath="~/.terraformrc" text="in the editor"></walkthrough-editor-spotlight>. This file is located at `~/.terraformrc`.

Paste the user token into that file like so:

```
credentials "app.terraform.io" {
  token = "REPLACE-ME"
}
```

Save and close this file, we don't need it again. You can read more about
configuring Terraform Cloud in [the documentation](https://www.terraform.io/docs/enterprise/free/index.html).

Now that you've configured your remote backend, run `terraform init` to setup
Terraform. It should ask if you want to migrate your state to Terraform Cloud.

```
$ terraform init

Initializing the backend...
Do you want to copy existing state to the new backend?
  Pre-existing state was found while migrating the previous "local" backend to the
  newly configured "remote" backend. No existing state was found in the newly
  configured "remote" backend. Do you want to copy this state to the new "remote"
  backend? Enter "yes" to copy and "no" to start with an empty state.

  Enter a value:
```

Say "yes" and Terraform will copy your state:

```
...

  Enter a value: yes

Releasing state lock. This may take a few moments...

Successfully configured the backend "remote"! Terraform will automatically
use this backend unless the backend configuration changes.

...
```

Now, if you run `terraform apply`, Terraform should state that there are no
changes:

```
$ terraform apply
# ...

Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

ip = 104.154.236.90
```

Terraform is now storing your state remotely in Terraform Cloud. Remote state
storage makes collaboration easier and keeps state and secret information off
your local disk. Remote state is loaded only in memory when it is used.

If you want to move back to local state, you can remove the backend
configuration block from your configuration and run `terraform init` again.
Terraform will once again ask if you want to migrate your state back to local.

## Destroying Infrastructure

We've now seen how to build and change infrastructure. Terraform also will destroy your Terraform-managed infrastructure as well.

Destroying your infrastructure is a rare event in production
environments. But if you're using Terraform to spin up multiple
environments such as development, test, and QA, then
destroying is often a useful action.

### Destroying Resources

When a resource is removed from your configuration, Terraform will notice next time you run `terraform plan` or `terraform apply` and destroy that resource. Remove the `"google_compute_instance" "vm_instance"` block from your `main.tf` file, and apply that change by running:

```
terraform apply
```

You should see that Terraform will destroy that instance if you answer `yes`. Go ahead and do so now.

### Terraform Destroy

Your entire configuration can be destroyed using the `terraform destroy` command, which is similar to `terraform apply` but it behaves as if all of the resources have been removed from the configuration. Run this command now:

```sh
terraform destroy
```

You should see output similar to this:

```
...
Plan: 0 to add, 0 to change, 3 to destroy.
Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.
  Enter a value:
...
```

The `-` prefix indicates that the instance and the network will be destroyed. As with apply, Terraform shows its execution plan and waits for approval before making any changes.

Answer `yes` to execute this plan and destroy the infrastructure:

```
Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

google_compute_instance.vm_instance: Destroying... [id=terraform-instance]
google_compute_instance.vm_instance: Still destroying... [id=terraform-instance, 10s elapsed]
...
google_compute_network.vpc_network: Still destroying... [id=terraform-network, 1m10s elapsed]
google_compute_network.vpc_network: Destruction complete after 1m17s

Destroy complete! Resources: 2 destroyed.
```

Just like with `apply`, Terraform determines the order in which things must be
destroyed. GCP won't allow a VPC network to be deleted if there are resources
still in it, so Terraform waits until the instance is destroyed before
destroying the network. When performing operations, Terraform creates a
dependency graph to determine the correct order of operations. In more
complicated cases with multiple resources, Terraform will perform operations in parallel when it's safe to do so.

## Terraform Enterprise

[Terraform Enterprise](https://www.hashicorp.com/products/terraform/?utm_source=oss&utm_medium=getting-started&utm_campaign=terraform) is a commercial solution which combines a predictable and reliable shared run environment with tools to help you work together on Terraform configurations and modules.

Although Terraform Enterprise can act as a standard remote backend to support Terraform runs on local machines, it works even better as a remote run environment. It supports two main workflows for performing Terraform runs:

- A VCS-driven workflow, in which it automatically queues plans whenever changes are committed to your configuration's VCS repo.
- An API-driven workflow, in which a CI pipeline or other automated tool can upload configurations directly.

For a hands-on introduction to Terraform Enterprise, [follow the Terraform Enterprise getting started guide](https://www.terraform.io/docs/enterprise/getting-started/index.html).

## Next Steps

That concludes the getting started guide for Terraform. Hopefully you're now
able to not only see what Terraform is useful for, but you're also able to put
this knowledge to use to improve building your own infrastructure.

We've covered the basics for all of these features in this guide.

As a next step, the following resources are available:

- [Documentation](https://www.terraform.io/docs/index.html) - The documentation is an in-depth reference guide to all the features of Terraform, including technical details about the internals of how Terraform operates.

- [Examples](https://www.terraform.io/intro/examples/index.html) - The examples have more full featured configuration files, showing some of the possibilities with Terraform.

- [Learn](https://learn.hashicorp.com) - Includes many more tutorials and guides to help you learn more about Terraform.
